{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Individual Parks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in our process was to scale down our analysis to the park level and examine CES servies offered by park. Since our methodology closely follows the Hale (2019) aricle, we needed to hand-code a select set of the tags into Hale's predefined CES buckets. To do this, we first coded the top 200 tags across all parks to get a sense of the types of services offered across all parks. The top 100 tags did not yield enough codeable tags, so we expanded that selection for a more robust sample. \n",
    "\n",
    "Tags themeselves are coded into one of the following categories (we did not cross-code, for parsimony, though we recognize that future analysis would yield more comprehensive results if tags could be cross-coded): existence, recreation, social relations, aesthetics, spritual, knowledge systems, inspiration, cultural heritage, education, sense of place, and culutral diversity. \n",
    "\n",
    "We coded parks that had at least 50 unique tags associated with that specific park. The coded parks are: MacArthur, Franklin Canyon, Hancock,Rio de Los Angeles, Runyon Canyon, Coldwater Creek, Cheviot Hills, and Angels Gate. We coded tags that fit into each of the above cateogories, but did not code tags that did not equate to a CES (i.e., nonsensical tags, vague tags, or tags for unidentifiable built infrastructure). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing parks csv\n",
    "import pandas as pd\n",
    "\n",
    "# You might need to add a path as well\n",
    "fn = 'parks_data.csv'\n",
    "parks_data = pd.read_csv(fn)\n",
    "parks_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "swords = [re.sub(r\"[^A-z\\s]\", \"\", sword) for sword in stopwords.words('english')]\n",
    "swords += ['losangeles', 'la', 'losangelesca', 'ca', 'macarthur', 'macarthurpark', 'woodley', 'riodelosangeles', 'runyoncanyon', \n",
    "           'temescalgateway', 'heidelbergpark', 'hancockpark', 'franklincanyonpark', 'franklincanyonpark', 'angelsgate', \n",
    "           'coldwatercanyon', 'chatsworthparksouth','cheviothills', 'california', 'usa', 'southerncalifornia', 'park', 'parklabrea', \n",
    "          'unitedstates', 'america']\n",
    "\n",
    "def clean_string(text):\n",
    "    # remove punctuation\n",
    "    text = re.sub(r\"[^A-z\\s]\", \"\", text)\n",
    "    \n",
    "    cleaned_list_of_words = [word for word in word_tokenize(text.lower()) if word not in swords] #return a string or apply to all tags\n",
    "    \n",
    "    return cleaned_list_of_words\n",
    "\n",
    "#calling the function to only apply to the tags column \n",
    "parks_data['tags'] = parks_data['tags'].apply(clean_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_data\n",
    "parks_data.parkname.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# category map codes by park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_CES = ['Existence','Recreation','Social Relations','Aesthetics', 'Knowledge Systems',\n",
    "              'Inspiration', 'Cultural Heritage','Education', 'Sense of Place','Cultural Diversity','Spiritual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Franklin Canyon Park\n",
    "category_map_franklincanyon = { 'Existence': ['santamonicamountains','franklincanyonlake','losangelesmountains','mayberrylake','myerslake','grass','lake','trees','ducks','water','evergreens','frog','woods'], \n",
    "                               'Recreation': ['rustythedog','canine','chihuahuamix','mutt','dog','pet','weeksfordogs','urbanhiking'],\n",
    "                               'Social Relations':[],\n",
    "                               'Aesthetics':['sky'], \n",
    "                               'Knowledge Systems':[],\n",
    "                               'Inspiration':[], \n",
    "                               'Cultural Heritage':[],\n",
    "                               'Education':[], \n",
    "                               'Sense of Place':[],\n",
    "                               'Cultural Diversity':[],\n",
    "                               'Spiritual':['nature','neature']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hancock park\n",
    "category_map_hancockpark = { 'Existence': ['garden','parks',], \n",
    "                               'Recreation': ['gardentour','fish'],\n",
    "                               'Social Relations':['gardenparty','people','picnik'],\n",
    "                               'Aesthetics':[], \n",
    "                               'Knowledge Systems':[],\n",
    "                               'Inspiration':[], \n",
    "                               'Cultural Heritage':['sculpture','art','statue'],\n",
    "                               'Education':['georgecpagemuseum','museums','losangelescountymuseumofart','iceage','pleistocene','skeletons',\n",
    "                                            'skulls','pit','tarpits','labreatarpits','labrea','museum','pagemuseum','fossils','bones','paleontology',\n",
    "                                           'lacma','animalsmammoths','excavation','sabretooth','tigers','giantgroundsloths','gettyhouse',\n",
    "                                           'tar','sabretoothtigers','olympusem','skeleton','fossil','mammoth','mastodon'], \n",
    "                               'Sense of Place':[],\n",
    "                               'Cultural Diversity':['lapride','westhollywoodpride','lagaypride','westhollywoodgaypride','losangelespride',\n",
    "                                                     'losangelesgaypride','pride','gaypride'],\n",
    "                               'Spiritual':['treasuresoflosangelesarchitecture']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rio del Los Angeles Park\n",
    "category_map_riodellosangeles = { 'Existence': ['lariver','losangelesriver','grass'], \n",
    "                               'Recreation': ['campout'],\n",
    "                               'Social Relations':['walkathon','earthday'],\n",
    "                               'Aesthetics':[], \n",
    "                               'Knowledge Systems':[],\n",
    "                               'Inspiration':[], \n",
    "                               'Cultural Heritage':['losangelesstatehistoricpark'],\n",
    "                               'Education':['environmentaljustice','urbanparkmovement'], \n",
    "                               'Sense of Place':[],\n",
    "                               'Cultural Diversity':[],\n",
    "                               'Spiritual':['outside']}\n",
    "#note: I recategorized grass into existence instead of aesthetics...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runyon Canyon Park\n",
    "category_map_runyon = { 'Existence': ['mountains','canyons','hills','mountains','hill','horse'], \n",
    "                               'Recreation': ['hiking','hike','sunriserunyon','sunriseinrunyon','sunriseinrunyoncanyonpark',\n",
    "                                              'trail','observatory','run','jog'],\n",
    "                               'Social Relations':[],\n",
    "                               'Aesthetics':['textures','texturemaps','texturemap','texture','sunset','sky','skyline',\n",
    "                                             'clouds','sun','weather','sunrise','pacificocean','panorama','color'], \n",
    "                               'Knowledge Systems':[],\n",
    "                               'Inspiration':[], \n",
    "                               'Cultural Heritage':[],\n",
    "                               'Education':[], \n",
    "                               'Sense of Place':[],\n",
    "                               'Cultural Diversity':[],\n",
    "                               'Spiritual':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coldwater Canyon Park\n",
    "category_map_runyon = { 'Existence': ['tujungawashgreenway','tujungawash','pacificocean'], \n",
    "                               'Recreation': ['summerolympics'],\n",
    "                               'Social Relations':['zurbulon'],\n",
    "                               'Aesthetics':['overlook','sunset','viewpoint','scenicoverview','mulhollandscenicoverview',\n",
    "                                             'brown','barbaraafineoverlook','lasunset','midcenturymodernhomes'], \n",
    "                               'Knowledge Systems':['lahistory','californiahistory'],\n",
    "                               'Inspiration':['mural'], \n",
    "                               'Cultural Heritage':['charliechaplin'],\n",
    "                               'Education':['losangelespubliclibrary'], \n",
    "                               'Sense of Place':[],\n",
    "                               'Cultural Diversity':[],\n",
    "                               'Spiritual':['church','littlebrownchurchinthevalley']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheviot Hills Park\n",
    "category_map_cheviothills = { 'Existence': ['sky','weather','tree','cloudy'], \n",
    "                               'Recreation': ['westerncup','sports','quidditch','nikon','nikond','dog','puggle',\n",
    "                                              'puppy','referee','boat'],\n",
    "                               'Social Relations':['harrypotter','wand'],\n",
    "                               'Aesthetics':['green','landscape'], \n",
    "                               'Knowledge Systems':[],\n",
    "                               'Inspiration':[], \n",
    "                               'Cultural Heritage':['parlance'],\n",
    "                               'Education':[], \n",
    "                               'Sense of Place':['geeks','geek','neighborhood'],\n",
    "                               'Cultural Diversity':[],\n",
    "                               'Spiritual':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing dataframe and converting to geodataframe using geometry column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ces_park_shapes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6b44ba38f5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ces_park_shapes.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mparks_sf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mparks_sf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ces_park_shapes.csv'"
     ]
    }
   ],
   "source": [
    "import geopandas as gdp \n",
    "import pandas as pd\n",
    "\n",
    "#read in csv file\n",
    "\n",
    "fn = 'ces_park_shapes.csv'\n",
    "parks_sf = pd.read_csv(fn)\n",
    "parks_sf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing shape file\n",
    "https://www.earthdatascience.org/workshops/gis-open-source-python/intro-vector-data-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/morganrogers/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/fiona/ogrext.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libtbb.dylib\n  Referenced from: /Users/morganrogers/opt/anaconda3/envs/UP229/lib/libtiledb.dylib\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dca9fe73d3de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msjer_plot_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Users/morganrogers/Documents/GitHub/LaParks_NLP/ces_laparks.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PATH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PATH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\";\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlibdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesCollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrvsupport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupported_drivers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensure_env_with_credentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mItemsIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeysIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mogrext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuffer_to_virtual_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_virtual_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGEOMETRY_TYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/morganrogers/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/fiona/ogrext.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libtbb.dylib\n  Referenced from: /Users/morganrogers/opt/anaconda3/envs/UP229/lib/libtiledb.dylib\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import fiona\n",
    "sjer_plot_locations = gpd.read_file('Users/morganrogers/Documents/GitHub/LaParks_NLP/ces_laparks.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Input file does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b8e8a90630e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# opening the vector map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\\\Users\\\\morganrogers\\\\Documents\\\\Github\\\\LaParks_NLP\\\\ces_laparks.shp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Input file does not exist.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# reading the shape file by using reader function of the shape lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input file does not exist."
     ]
    }
   ],
   "source": [
    "import shapefile as shp\n",
    "#/Users/morganrogers/Documents/GitHub/LaParks_NLP/ces_laparks.shp\n",
    "\n",
    "# opening the vector map\n",
    "shp_path = \"\\\\Users\\\\morganrogers\\\\Documents\\\\Github\\\\LaParks_NLP\\\\ces_laparks.shp\"\n",
    "assert os.path.exists(shp_path), \"Input file does not exist.\"\n",
    "\n",
    "# reading the shape file by using reader function of the shape lib\n",
    "sf = shp.Reader(shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ShapefileException",
     "evalue": "Unable to open shapefiles/ces_laparks.dbf or shapefiles/ces_laparks.shp.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mShapefileException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5ea731cdc212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshapefile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapefile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shapefiles/ces_laparks.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/shapefile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# Otherwise, load from separate shp/shx/dbf args (must be file-like)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/shapefile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, shapefile)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapeName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mShapefileException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to open %s.dbf or %s.shp.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshapeName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapeName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__shpHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mShapefileException\u001b[0m: Unable to open shapefiles/ces_laparks.dbf or shapefiles/ces_laparks.shp."
     ]
    }
   ],
   "source": [
    "import shapefile\n",
    "\n",
    "sf = shapefile.Reader(\"shapefiles/ces_laparks.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "the 'read_file' function requires the 'fiona' package, but it is not installed or does not import correctly.\nImporting fiona resulted in: dlopen(/Users/morganrogers/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/fiona/ogrext.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libtbb.dylib\n  Referenced from: /Users/morganrogers/opt/anaconda3/envs/UP229/lib/libtiledb.dylib\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d99c96a098fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/morganrogers/Documents/GitHub/LaParks_NLP/ces_laparks.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mby\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0m_check_fiona\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'read_file' function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_check_fiona\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfiona\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         raise ImportError(\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;34mf\"the {func} requires the 'fiona' package, but it is not installed or does \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;34mf\"not import correctly.\\nImporting fiona resulted in: {fiona_import_error}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: the 'read_file' function requires the 'fiona' package, but it is not installed or does not import correctly.\nImporting fiona resulted in: dlopen(/Users/morganrogers/opt/anaconda3/envs/UP229/lib/python3.7/site-packages/fiona/ogrext.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libtbb.dylib\n  Referenced from: /Users/morganrogers/opt/anaconda3/envs/UP229/lib/libtiledb.dylib\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "sf = gpd.read_file('/Users/morganrogers/Documents/GitHub/LaParks_NLP/ces_laparks.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import earthpy as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/morganrogers/ces_laparks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-74543d6bf012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#download data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHOME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ces_laparks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/morganrogers/ces_laparks'"
     ]
    }
   ],
   "source": [
    "#download data\n",
    "os.chdir(os.path.join(et.io.HOME, 'ces_laparks'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MacArthur Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "macarthur = parks_data['parkname']=='macarthur'\n",
    "macarthur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macarthur_tags = parks_data[macarthur]\n",
    "print(macarthur_tags)\n",
    "macarthur_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = macarthur_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_macarthur.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of spread of CES and strength of each CES - macarthur park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import macarthur top tags\n",
    "fn = 'top_tags_macarthur.csv'\n",
    "macarthur_tags = pd.read_csv(fn)\n",
    "macarthur_tags.head()\n",
    "\n",
    "# import CES code breakdown for macarthur park\n",
    "fn2 = 'codes_macarthur2.csv'\n",
    "macarthur_ces = pd.read_csv(fn2)\n",
    "macarthur_ces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaNs with 0\n",
    "\n",
    "macarthur_ces.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. group by CES and count size\n",
    "2. assign to new df to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macarthur_ces.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of columns from the original dataframe, excluding the ones that aren't about ces\n",
    "cols = [col for col in macarthur_ces.columns if col not in ['Words']]\n",
    "\n",
    "# normalize the data by dividing each column by the total tag counts (1682)\n",
    "for col in cols:\n",
    "    macarthur_ces[col] = macarthur_ces[col].sum()\n",
    "    \n",
    "ces = macarthur_ces[cols]/1682*100\n",
    "print(ces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trouble getting overall percentage for each group --> trying a different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop words column\n",
    "macarthur_ces.drop(columns=['Words'])\n",
    "\n",
    "#sum of each ces\n",
    "sum_ces = macarthur_ces.sum(axis=0)\n",
    "print(sum_ces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert series to dataframe and keep index\n",
    "# https://www.geeksforgeeks.org/convert-given-pandas-series-into-a-dataframe-with-its-index-as-another-column-on-the-dataframe/\n",
    "\n",
    "cesDf = sum_ces.to_frame().reset_index()\n",
    "print(cesDf)\n",
    "list(cesDf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in macarthur_ces.columns if col not in ['index']]\n",
    "\n",
    "ces_total = cesDf[cols]/1682*100\n",
    "print(ces_total)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# rename columns\n",
    "cesDf.columns=['ces','total']\n",
    "print(cesDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up df by droping row 0 and renaming columns\n",
    "\n",
    "#drop row by index\n",
    "cesDf.drop(labels=[\"Words\"],axis=0,inplace=False)\n",
    "print(cesDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide each column by total tag counts 1682 and multiply by 100 to normalize the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Woodley Park\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "woodley = parks_data['parkname']=='woodley'\n",
    "woodley.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woodley_tags = parks_data[woodley]\n",
    "print(woodley_tags)\n",
    "woodley_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = woodley_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_woodley.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rio de Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "riodelosangeles = parks_data['parkname']=='riodelosangeles'\n",
    "riodelosangeles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riodelosangeles_tags = parks_data[riodelosangeles]\n",
    "print(riodelosangeles_tags)\n",
    "riodelosangeles_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = riodelosangeles_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_riodelosangeles.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runyon Canyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "runyoncanyon = parks_data['parkname']=='runyoncanyon'\n",
    "runyoncanyon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runyoncanyon_tags = parks_data[runyoncanyon]\n",
    "print(runyoncanyon_tags)\n",
    "runyoncanyon_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = runyoncanyon_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_runyoncanyon.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temescal Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "temescalgateway = parks_data['parkname']=='temescalgateway'\n",
    "temescalgateway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temescalgateway_tags = parks_data[temescalgateway]\n",
    "print(temescalgateway_tags)\n",
    "temescalgateway_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = temescalgateway_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_temescalgateway.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heidelberg Park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hancock Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "hancockpark = parks_data['parkname']=='hancockpark'\n",
    "hancockpark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hancockpark_tags = parks_data[hancockpark]\n",
    "print(hancockpark_tags)\n",
    "hancockpark_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = hancockpark_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_hancockpark.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Franklin Canyon Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "franklincanyonpark = parks_data['parkname']=='franklincanyonpark'\n",
    "franklincanyonpark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franklincanyonpark_tags = parks_data[franklincanyonpark]\n",
    "print(franklincanyonpark_tags)\n",
    "franklincanyonpark_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = franklincanyonpark_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_franklincanyonpark.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angels Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "angelsgate = parks_data['parkname']=='angelsgate'\n",
    "angelsgate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angelsgate_tags = parks_data[angelsgate]\n",
    "print(angelsgate_tags)\n",
    "angelsgate_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = angelsgate_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_angelsgate.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coldwater Canyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "coldwatercanyon = parks_data['parkname']=='coldwatercanyon'\n",
    "coldwatercanyon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldwatercanyon_tags = parks_data[coldwatercanyon]\n",
    "print(coldwatercanyon_tags)\n",
    "coldwatercanyon_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = coldwatercanyon_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_coldwatercanyon.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheviot Hills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "cheviothills = parks_data['parkname']=='cheviothills'\n",
    "cheviothills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheviothills_tags = parks_data[cheviothills]\n",
    "print(cheviothills_tags)\n",
    "cheviothills_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = cheviothills_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_cheviothills.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatsworth Park South"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
