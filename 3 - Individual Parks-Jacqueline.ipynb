{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Individual Parks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Methodology\n",
    "\n",
    "The next step in our process was to scale down our analysis to the park level and examine CES servies offered by park. Since our methodology closely follows the Hale (2019) aricle, we needed to hand-code a select set of the tags into Hale's predefined CES buckets. To do this, we first coded the top 200 tags across all parks to get a sense of the types of services offered across all parks. The top 100 tags did not yield enough codeable tags, so we expanded that selection for a more robust sample. The next step was to download separate CSV files for each park we intended to hand-code. We decided to only code parks that had 50 or more unique tags. The parks that fit this criteria were: MacArthur Park, Runyon Canyon, Angel's Gate, Cheviot Hills, Coldwater Canyon, Franklin Canyon, Hancock Park, and Rio de Los Angeles. We coded each of these CSV files separately and added them, by hand, to a dictionary that contained each tag and its respective CES bucket (you can find that code below)\n",
    "\n",
    "Tags themeselves are coded into one of the following categories (we did not cross-code, for parsimony, though we recognize that future analysis would yield more comprehensive results if tags could be cross-coded): existence, recreation, social relations, aesthetics, spritual, knowledge systems, inspiration, cultural heritage, education, sense of place, and culutral diversity. \n",
    "\n",
    "*Existence*: relates to wildlife or natural phenomenon, such as wild animals, trees or lakes. \n",
    "*Recreation*: relates to tags that encompass hobbies or leisure activities, such as boating, sports, or photography.\n",
    "*Social Relations*: consist of activities that promote social cohesion and camaraderie, such as weddings or famliy activities.\n",
    "*Aesthetics*: relate to tags that encompass beauty, such as scenic overlooks, sunsets, or architecture. Spiritual tags are bucketed based on religious or faith-based activities, such as attending church or a worship ceremony. \n",
    "*Knowledge Systems*: encompass collective learning or educational activities, such as birdwatching or visiting a museum.\n",
    "*Inspiration*: relates to activiteis that promote self-reflection, such as examining a work of art or reflecting on one's surroundings.\n",
    "*Cultural Heritage*: relates to activites centered on ethnic identities and groups, such as festivals or looking at historic monuments.\n",
    "*Education*: relates to learning, and may center on visiting a library or an exibit in a museum. \n",
    "Sense of place refers to activitives that connect communities and neighborhoods through cultural activities or shared history.\n",
    "*Cultural Diversity*: relates to activites that bring together specigic groups, such as LGBTQIA+ events or Native American cultural events.  \n",
    "\n",
    "We coded tags that fit into each of the above cateogories, but did not code tags that did not equate to a CES (i.e., nonsensical tags, vague tags, or tags for unidentifiable built infrastructure). You can follow the process below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing parks csv\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "/Users/jacquelineadams/Documents/GitHub/LaParks_NLP_5/LaParks_NLP/ces_laparks.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: /Users/jacquelineadams/Documents/GitHub/LaParks_NLP_5/LaParks_NLP/ces_laparks.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7c6bb2be559a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import parks shapefile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparks_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/jacquelineadams/Documents/GitHub/LaParks_NLP_5/LaParks_NLP/ces_laparks.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0m\u001b[1;32m    257\u001b[0m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: /Users/jacquelineadams/Documents/GitHub/LaParks_NLP_5/LaParks_NLP/ces_laparks.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "#import parks shapefile\n",
    "import geopandas as gpd\n",
    "parks_shape = gpd.read_file('/Users/jacquelineadams/Documents/GitHub/LaParks_NLP_5/LaParks_NLP/ces_laparks.shp')\n",
    "\n",
    "\n",
    "#import shapefile as shp\n",
    "#/Users/morganrogers/Documents/GitHub/LaParks_NLP/ces_laparks.shp\n",
    "# opening the vector map\n",
    "#shp_path = \"/Users/jacquelineadams/Documents/GitHub/LaParks_NLP_5/ces_laparks.shp\"\n",
    "#assert os.path.exists(shp_path), \"Input file does not exist.\"\n",
    "# reading the shape file by using reader function of the shape lib\n",
    "#sf = shp.Reader(shp_path)\n",
    "\n",
    "parks_shape.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "swords = [re.sub(r\"[^A-z\\s]\", \"\", sword) for sword in stopwords.words('english')]\n",
    "swords += ['losangeles', 'la', 'losangelesca', 'ca', 'macarthur', 'macarthurpark', 'woodley', 'riodelosangeles', 'runyoncanyon', \n",
    "           'temescalgateway', 'heidelbergpark', 'hancockpark', 'franklincanyonpark', 'franklincanyonpark', 'angelsgate', \n",
    "           'coldwatercanyon', 'chatsworthparksouth','cheviothills', 'california', 'usa', 'southerncalifornia', 'park', 'parklabrea', \n",
    "          'unitedstates', 'america']\n",
    "\n",
    "def clean_string(text):\n",
    "    # remove punctuation\n",
    "    text = re.sub(r\"[^A-z\\s]\", \"\", text)\n",
    "    \n",
    "    cleaned_list_of_words = [word for word in word_tokenize(text.lower()) if word not in swords] #return a string or apply to all tags\n",
    "    \n",
    "    return cleaned_list_of_words\n",
    "\n",
    "#calling the function to only apply to the tags column \n",
    "parks_data['tags'] = parks_data['tags'].apply(clean_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_data\n",
    "parks_data.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = { 'Existence': ['westlake', 'lake','palmtrees','palms','elks','parkplaza','birds','palmtree', 'santamonicamountains','franklincanyonlake','losangelesmountains','mayberrylake','myerslake','grass','lake','trees','ducks','water','evergreens','frog','woods', 'ice', 'fluids','iceblocks','blocksofice','wallofice','harbor', 'sky', 'weather','tree','cloudy','garden','parks','lariver','losangelesriver','grass','mountains','canyons','hills','mountains','hill','horse','tujungawashgreenway','tujungawash','pacificocean','sky','weather','tree','cloudy'], \n",
    "                'Recreation': ['music','bikes','lilihaydn','bicycles','violin','ciclovia','loslobos','event', 'rustythedog','canine','chihuahuamix','mutt','dog','pet','weeksfordogs','urbanhiking', 'costumes', 'costume', 'cosplay', 'boomerang', 'lighthouse','westerncup','sports', 'quidditch', 'dog', 'puggle', 'puppy', 'referee', 'boat', 'nikon', 'nikond','gardentour','fish','campout','hiking','hike','sunriserunyon','sunriseinrunyon','sunriseinrunyoncanyonpark','trail','observatory','run','jog','summerolympics','westerncup','sports','quidditch','nikon','nikond','dog','puggle','puppy','referee','boat'], \n",
    "                'Social Relations': ['ciclavia','rally','protest','keepfamliestogethor','tamale','asada','alpastor','march','carnitas','eltaurino','burrito','thegreattacohunt','lasantacon','people','tacos','food','harrypotter', 'wand', 'geeks', 'geek','gardenparty','people','picnik','walkathon','earthday','zurbulon','harrypotter','wand'],\n",
    "                'Aesthetics': ['colorful','green', 'landscape','textures','texturemaps','texturemap','texture','sunset','sky','skyline','clouds','sun','weather','sunrise','pacificocean','panorama','color','overlook','sunset','viewpoint','scenicoverview','mulhollandscenicoverview','brown','barbaraafineoverlook','lasunset','green','landscape'],\n",
    "                'Spiritual': ['signs','sanity','nature','neature','harborinterfaith','outside','church','littlebrownchurchinthevalley'], \n",
    "                'Inspiration':['art','portraitsofhope','publicart', 'artonthewaterfront', 'artist', 'sculpture', 'printmaking', 'portrait', 'contemporaryart', 'painting', 'polaroid', 'draw', 'photographer', 'studioartist', 'prints','mural'],\n",
    "                'Cultural Heritage': ['landmark','monument', 'curlettandbeelman','fortmacarthur','warreinactment', 'agcc', 'angelsgateculturalcenter', 'openstudios', 'allankaprow', 'gallerya', 'artgallery', 'gallery', 'artexhibition', 'slobodandimitrov', 'culturalcenter', 'exhibition', 'downstairsgallery', 'installation', 'hillarybradfield', 'festival','parlance','sculpture','art','statue','treasuresoflosangelesarchitecture','losangelesstatehistoricpark','midcenturymodernhomes','charliechaplin','parlance'],\n",
    "                'Sense of Place': ['neighborhood','community','eccideasclub', 'sanpedro', 'neighborhood'], \n",
    "                'Cultural Diversity': ['mexican','lengua','march','immigration','czechart','lapride','westhollywoodpride','lagaypride','westhollywoodgaypride','losangelespride','losangelesgaypride','pride','gaypride'],\n",
    "                'Knowledge Systems': ['historyofsanpedropunk', 'belleepoque','lahistory','californiahistory'],\n",
    "                'Education': ['portoflosangeles', 'port','portofla','marshallastor','berth','georgecpagemuseum','museums','losangelescountymuseumofart','iceage','pleistocene','skeletons','skulls','pit','tarpits','labreatarpits','labrea','museum','pagemuseum','fossils','bones','paleontology','lacma','animalsmammoths','excavation','sabretooth','tigers','giantgroundsloths','gettyhouse','tar','sabretoothtigers','olympusem','skeleton','fossil','mammoth','mastodon','environmentaljustice','urbanparkmovement','losangelespubliclibrary'\n",
    "                             ]}\n",
    "\n",
    "# Import the csv of frequencies for each park under consideration\n",
    "fns = ['top_tags_angelsgate.csv','top_tags_cheviothills.csv','top_tags_coldwatercanyon.csv',\n",
    "       'top_tags_franklincanyonpark.csv','top_tags_hancockpark.csv','top_tags_macarthur.csv',\n",
    "       'top_tags_riodelosangeles.csv','top_tags_runyoncanyon.csv']\n",
    "parks_frequency = []\n",
    "for fn in fns: \n",
    "    parks_frequency.append(pd.read_csv(fn))\n",
    "\n",
    "#print(parks_frequency)\n",
    "\n",
    "# Create a function to loop over the categories and sum the words associated with each category  \n",
    "def getCategories(frequencyDf):\n",
    "    \n",
    "    category_frequencies = dict.fromkeys(category_map,0)\n",
    "    \n",
    "    for index, row in frequencyDf.iterrows():\n",
    "        #print(row['tags'],row['value'])\n",
    "        for category_name in category_map:\n",
    "            wordlist = category_map[category_name]\n",
    "            if row['tags'] in wordlist:\n",
    "                category_frequencies[category_name]+=row['value']\n",
    "            \n",
    "    return category_frequencies\n",
    "    \n",
    "# Create a list of dictionaries with the frequencies by category for each park\n",
    "cat_frequencies = []\n",
    "for park in parks_frequency:\n",
    "    cat_frequencies.append(getCategories(park))\n",
    "\n",
    "print(cat_frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rio de Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "riodelosangeles = parks_data['parkname']=='riodelosangeles'\n",
    "riodelosangeles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riodelosangeles_tags = parks_data[riodelosangeles]\n",
    "print(riodelosangeles_tags)\n",
    "riodelosangeles_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = riodelosangeles_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a geometry column\n",
    "import geopandas as gpd\n",
    "riodelosangelesgdf = gpd.GeoDataFrame(\n",
    "    macarthur_photos, geometry=gpd.points_from_xy(macarthur_photos.longitude, macarthur_photos.latitude, crs='EPSG:4326'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapped tags associated with MacArthur Park\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(5,10))\n",
    "macarthurgdf.to_crs('EPSG:3857').plot(color='r', ax=ax) # remember, 3857 is Web Mercator\n",
    "# let's add a basemap using the contextily library\n",
    "ctx.add_basemap(ax, zoom=12)\n",
    "# and we really don't need the axis ticks and labels, so we set them to an empty list\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_riodelosangeles.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runyon Canyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "runyoncanyon = parks_data['parkname']=='runyoncanyon'\n",
    "runyoncanyon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runyoncanyon_tags = parks_data[runyoncanyon]\n",
    "print(runyoncanyon_tags)\n",
    "runyoncanyon_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = runyoncanyon_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_runyoncanyon.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temescal Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "temescalgateway = parks_data['parkname']=='temescalgateway'\n",
    "temescalgateway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temescalgateway_tags = parks_data[temescalgateway]\n",
    "print(temescalgateway_tags)\n",
    "temescalgateway_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = temescalgateway_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_temescalgateway.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heidelberg Park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hancock Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "hancockpark = parks_data['parkname']=='hancockpark'\n",
    "hancockpark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hancockpark_tags = parks_data[hancockpark]\n",
    "print(hancockpark_tags)\n",
    "hancockpark_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = hancockpark_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_hancockpark.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Franklin Canyon Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "franklincanyonpark = parks_data['parkname']=='franklincanyonpark'\n",
    "franklincanyonpark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franklincanyonpark_tags = parks_data[franklincanyonpark]\n",
    "print(franklincanyonpark_tags)\n",
    "franklincanyonpark_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = franklincanyonpark_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_franklincanyonpark.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angels Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "angelsgate = parks_data['parkname']=='angelsgate'\n",
    "angelsgate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angelsgate_tags = parks_data[angelsgate]\n",
    "print(angelsgate_tags)\n",
    "angelsgate_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = angelsgate_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_angelsgate.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coldwater Canyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "coldwatercanyon = parks_data['parkname']=='coldwatercanyon'\n",
    "coldwatercanyon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldwatercanyon_tags = parks_data[coldwatercanyon]\n",
    "print(coldwatercanyon_tags)\n",
    "coldwatercanyon_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = coldwatercanyon_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_coldwatercanyon.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheviot Hills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out how to filter by parkname and retain the tags info by photo\n",
    "cheviothills = parks_data['parkname']=='cheviothills'\n",
    "cheviothills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheviothills_tags = parks_data[cheviothills]\n",
    "print(cheviothills_tags)\n",
    "cheviothills_tags.parkname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['tags', 'parkname']\n",
    "tag_park = cheviothills_tags[cols].explode('tags', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with count of each tag \n",
    "tag_park['value'] = [1] * tag_park.shape[0]\n",
    "\n",
    "#return top 100 most used tags sorted by value\n",
    "top_100_tags = tag_park.groupby('tags').sum().sort_values('value', ascending=False).head(100)\n",
    "\n",
    "#so we can view all tags\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting top 100 tags to a csv for hand coding \n",
    "top_100_tags.to_csv('top_tags_cheviothills.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatsworth Park South"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
